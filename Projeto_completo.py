# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E2ppvPzYTcYZ5jXvMfrv_FmJ2ve6Jl24
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
import warnings
warnings.filterwarnings('ignore')

print("=== PROJETO DE MINERAÇÃO DE DADOS ===")
print("Análise de Qualidade do Vinho")
print("=" * 50)

# 1. GERAÇÃO DOS DADOS
print("\n1. CARREGAMENTO DOS DADOS")
print("-" * 30)

# Criando dataset sintético baseado no Wine Quality
np.random.seed(42)
n_samples = 1000

# Gerando características do vinho
data = {
    'fixed_acidity': np.random.normal(8.3, 1.7, n_samples),
    'volatile_acidity': np.random.normal(0.53, 0.18, n_samples),
    'citric_acid': np.random.normal(0.27, 0.19, n_samples),
    'residual_sugar': np.random.lognormal(0.5, 1.0, n_samples),
    'chlorides': np.random.normal(0.087, 0.047, n_samples),
    'free_sulfur_dioxide': np.random.normal(15.9, 10.5, n_samples),
    'total_sulfur_dioxide': np.random.normal(46.5, 32.9, n_samples),
    'density': np.random.normal(0.9967, 0.0019, n_samples),
    'pH': np.random.normal(3.31, 0.15, n_samples),
    'sulphates': np.random.normal(0.66, 0.17, n_samples),
    'alcohol': np.random.normal(10.4, 1.1, n_samples)
}

# Criando variável de qualidade baseada nas características
quality_score = (
    data['alcohol'] * 0.3 +
    (1 / (data['volatile_acidity'] + 0.1)) * 0.2 +
    data['citric_acid'] * 0.15 +
    data['sulphates'] * 0.2 +
    (1 / (data['chlorides'] + 0.01)) * 0.15
)

# Convertendo para categorias
quality_labels = []
for score in quality_score:
    if score < np.percentile(quality_score, 33):
        quality_labels.append('Baixa')
    elif score < np.percentile(quality_score, 66):
        quality_labels.append('Média')
    else:
        quality_labels.append('Alta')

data['quality'] = quality_labels
df = pd.DataFrame(data)

print(f"Dataset criado com {len(df)} registros e {len(df.columns)} colunas")
print(f"\nPrimeiras 5 linhas:")
print(df.head())

print(f"\nDistribuição da qualidade:")
print(df['quality'].value_counts())

# 2. ANÁLISE EXPLORATÓRIA
print("\n2. ANÁLISE EXPLORATÓRIA")
print("-" * 30)

# Estatísticas básicas
print("Estatísticas descritivas:")
print(df.describe())

# Visualizações
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Análise Exploratória dos Dados', fontsize=14)

# Gráfico 1: Distribuição da qualidade
quality_counts = df['quality'].value_counts()
axes[0, 0].bar(quality_counts.index, quality_counts.values)
axes[0, 0].set_title('Distribuição da Qualidade')
axes[0, 0].set_ylabel('Quantidade')

# Gráfico 2: Álcool por qualidade
for quality in df['quality'].unique():
    subset = df[df['quality'] == quality]
    axes[0, 1].hist(subset['alcohol'], alpha=0.7, label=quality)
axes[0, 1].set_title('Distribuição do Álcool por Qualidade')
axes[0, 1].set_xlabel('Álcool (%)')
axes[0, 1].legend()

# Gráfico 3: Acidez volátil por qualidade
for quality in df['quality'].unique():
    subset = df[df['quality'] == quality]
    axes[1, 0].hist(subset['volatile_acidity'], alpha=0.7, label=quality)
axes[1, 0].set_title('Acidez Volátil por Qualidade')
axes[1, 0].set_xlabel('Acidez Volátil')
axes[1, 0].legend()

# Gráfico 4: Correlação (apenas variáveis numéricas)
numeric_cols = df.select_dtypes(include=[np.number]).columns
corr_matrix = df[numeric_cols].corr()
im = axes[1, 1].imshow(corr_matrix, cmap='coolwarm', aspect='auto')
axes[1, 1].set_title('Matriz de Correlação')
axes[1, 1].set_xticks(range(len(numeric_cols)))
axes[1, 1].set_yticks(range(len(numeric_cols)))
axes[1, 1].set_xticklabels(numeric_cols, rotation=45)
axes[1, 1].set_yticklabels(numeric_cols)

plt.tight_layout()
plt.show()

# 3. PREPARAÇÃO DOS DADOS
print("\n3. PREPARAÇÃO DOS DADOS")
print("-" * 30)

# Separando features e target
X = df.drop('quality', axis=1)
y = df['quality']

# Codificando a variável target
le = LabelEncoder()
y_encoded = le.fit_transform(y)

print(f"Features: {X.shape}")
print(f"Target: {y.shape}")
print(f"Classes: {le.classes_}")

# Divisão treino/teste (sem estratificação para evitar erros)
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.3, random_state=42
)

print(f"Treino: {X_train.shape}")
print(f"Teste: {X_test.shape}")

# Normalização
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Dados normalizados!")

# 4. MODELAGEM
print("\n4. APLICAÇÃO DOS ALGORITMOS")
print("-" * 30)

# Testando diferentes modelos
models = {
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)
}

results = {}

for name, model in models.items():
    print(f"\nTreinando {name}...")

    # Usando dados normalizados para Logistic Regression
    if name == 'Logistic Regression':
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    results[name] = accuracy

    print(f"Acurácia: {accuracy:.4f}")

# Melhor modelo
best_model_name = max(results, key=results.get)
print(f"\nMelhor modelo: {best_model_name}")
print(f"Acurácia: {results[best_model_name]:.4f}")

# 5. ANÁLISE DETALHADA
print("\n5. ANÁLISE DETALHADA DO MELHOR MODELO")
print("-" * 30)

# Retreinando o melhor modelo
if best_model_name == 'Random Forest':
    best_model = RandomForestClassifier(n_estimators=100, random_state=42)
    best_model.fit(X_train, y_train)
    y_pred_best = best_model.predict(X_test)

    # Importância das features
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False)

    print("Top 5 features mais importantes:")
    print(feature_importance.head())

else:
    best_model = LogisticRegression(random_state=42, max_iter=1000)
    best_model.fit(X_train_scaled, y_train)
    y_pred_best = best_model.predict(X_test_scaled)

# Convertendo predições de volta para labels
y_test_labels = le.inverse_transform(y_test)
y_pred_labels = le.inverse_transform(y_pred_best)

# Relatório de classificação
print(f"\nRelatório de Classificação:")
print(classification_report(y_test_labels, y_pred_labels))

# Matriz de confusão
cm = confusion_matrix(y_test_labels, y_pred_labels)
print(f"\nMatriz de Confusão:")
print(cm)

# 6. VISUALIZAÇÕES DOS RESULTADOS
print("\n6. VISUALIZAÇÕES DOS RESULTADOS")
print("-" * 30)

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Resultados da Análise', fontsize=14)

# Gráfico 1: Comparação de modelos
model_names = list(results.keys())
accuracies = list(results.values())
axes[0, 0].bar(model_names, accuracies, color=['skyblue', 'lightcoral'])
axes[0, 0].set_title('Acurácia dos Modelos')
axes[0, 0].set_ylabel('Acurácia')
axes[0, 0].set_ylim(0, 1)

# Adicionando valores nas barras
for i, v in enumerate(accuracies):
    axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center')

# Gráfico 2: Importância das features (se Random Forest)
if best_model_name == 'Random Forest':
    top_features = feature_importance.head(6)
    axes[0, 1].barh(range(len(top_features)), top_features['importance'])
    axes[0, 1].set_yticks(range(len(top_features)))
    axes[0, 1].set_yticklabels(top_features['feature'])
    axes[0, 1].set_title('Importância das Features')

# Gráfico 3: Matriz de confusão
im = axes[1, 0].imshow(cm, cmap='Blues')
axes[1, 0].set_title('Matriz de Confusão')
axes[1, 0].set_xlabel('Predito')
axes[1, 0].set_ylabel('Real')

# Adicionando números na matriz
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        axes[1, 0].text(j, i, str(cm[i, j]), ha='center', va='center')

# Gráfico 4: Distribuição das predições
pred_counts = pd.Series(y_pred_labels).value_counts()
axes[1, 1].bar(pred_counts.index, pred_counts.values)
axes[1, 1].set_title('Distribuição das Predições')
axes[1, 1].set_ylabel('Quantidade')

plt.tight_layout()
plt.show()

# 7. RESULTADOS FINAIS
print("\n7. RESUMO DOS RESULTADOS")
print("-" * 30)
print(f"Dataset: {len(df)} registros, {len(df.columns)-1} features")
print(f"Técnica: Classificação")
print(f"Melhor modelo: {best_model_name}")
print(f"Acurácia: {results[best_model_name]:.1%}")
print(f"Classes: {list(le.classes_)}")

if best_model_name == 'Random Forest':
    print(f"Feature mais importante: {feature_importance.iloc[0]['feature']}")

print("\nAnálise concluída com sucesso!")
print("=" * 50)